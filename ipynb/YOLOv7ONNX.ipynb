{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"sSDOngglBk_O","outputId":"1ab904a0-b9d0-46cd-ba26-297be83a3e0c"},"outputs":[],"source":["#https://github.com/WongKinYiu/yolov7\n","\n","!pip install --upgrade setuptools pip --user\n","!pip install onnx\n","!pip install onnxruntime\n","#!pip install --ignore-installed PyYAML\n","#!pip install Pillow\n","\n","!pip install protobuf<4.21.3\n","!pip install onnxruntime-gpu\n","!pip install onnx>=1.9.0\n","!pip install onnx-simplifier>=0.3.6 --user"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hQ5fNost-gZI","outputId":"396d7243-b6af-4acf-e555-38a984cd69bb"},"outputs":[],"source":["import sys\n","import torch\n","print(f\"Python version: {sys.version}, {sys.version_info} \")\n","print(f\"Pytorch version: {torch.__version__} \")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"feCaRUEI-_Os","outputId":"7a488cf8-f7d7-4366-ce12-442329a9266b"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yfZALjuo-_Md","outputId":"ccda5b64-a800-4c4a-bcb9-c7e899280751"},"outputs":[],"source":["!# Download YOLOv7 code\n","!git clone https://github.com/WongKinYiu/yolov7\n","%cd yolov7\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eWlHa1NJ-_Jw","outputId":"d32d8c3e-1d32-4ec9-bc41-d3e0f9d60497"},"outputs":[],"source":["!# Download trained weights\n","!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UX7u8eqj-_Hi","outputId":"8fc1e981-e105-4c71-e964-bcb3a927ad8d"},"outputs":[],"source":["!python detect.py --weights ./yolov7-tiny.pt --conf 0.25 --img-size 640 --source inference/images/horses.jpg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":529},"id":"wZD-nZXX-_Ez","outputId":"7486afe2-bbbb-4c12-898a-7d750dd14287"},"outputs":[],"source":["from PIL import Image\n","Image.open('/content/yolov7/runs/detect/exp/horses.jpg')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VaPGM88g-_CE","outputId":"c0abb5d2-b0db-4f14-9eaa-8adfdca807bf"},"outputs":[],"source":["# export ONNX for ONNX inference\n","%cd /content/yolov7/\n","!python export.py --weights ./yolov7-tiny.pt \\\n","        --grid --end2end --simplify \\\n","        --topk-all 100 --iou-thres 0.65 --conf-thres 0.35 \\\n","        --img-size 640 640 --max-wh 640 # For onnxruntime, you need to specify this value as an integer, when it is 0 it means agnostic NMS,\n","                     # otherwise it is non-agnostic NMS"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h9lzPkMxu7B8","outputId":"4aeff7ba-ff05-43f0-f725-868ec5b194ba"},"outputs":[],"source":["# show ONNX model\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ifw8pYU11Ske"},"outputs":[],"source":["# Inference for ONNX model\n","import cv2\n","cuda = True\n","w = \"/content/yolov7/yolov7-tiny.onnx\"\n","img = cv2.imread('/content/yolov7/inference/images/horses.jpg')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ipHqto0J0kkq"},"outputs":[],"source":["import cv2\n","import time\n","import requests\n","import random\n","import numpy as np\n","import onnxruntime as ort\n","from PIL import Image\n","from pathlib import Path\n","from collections import OrderedDict,namedtuple\n","\n","providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if cuda else ['CPUExecutionProvider']\n","session = ort.InferenceSession(w, providers=providers)\n","\n","\n","def letterbox(im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleup=True, stride=32):\n","    # Resize and pad image while meeting stride-multiple constraints\n","    shape = im.shape[:2]  # current shape [height, width]\n","    if isinstance(new_shape, int):\n","        new_shape = (new_shape, new_shape)\n","\n","    # Scale ratio (new / old)\n","    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n","    if not scaleup:  # only scale down, do not scale up (for better val mAP)\n","        r = min(r, 1.0)\n","\n","    # Compute padding\n","    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n","    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n","\n","    if auto:  # minimum rectangle\n","        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n","\n","    dw /= 2  # divide padding into 2 sides\n","    dh /= 2\n","\n","    if shape[::-1] != new_unpad:  # resize\n","        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n","    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n","    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n","    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n","    return im, r, (dw, dh)\n","\n","names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n","         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n","         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n","         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n","         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n","         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n","         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n","         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n","         'hair drier', 'toothbrush']\n","colors = {name:[random.randint(0, 255) for _ in range(3)] for i,name in enumerate(names)}\n","\n","img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","image = img.copy()\n","image, ratio, dwdh = letterbox(image, auto=False)\n","image = image.transpose((2, 0, 1))\n","image = np.expand_dims(image, 0)\n","image = np.ascontiguousarray(image)\n","\n","im = image.astype(np.float32)\n","im /= 255\n","im.shape\n","\n","outname = [i.name for i in session.get_outputs()]\n","outname\n","\n","inname = [i.name for i in session.get_inputs()]\n","inname\n","\n","inp = {inname[0]:im}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"07vh3pUa1ccC","outputId":"10e8169b-611d-4fd5-d3a7-aa1e7992f077"},"outputs":[],"source":["# ONNX inference\n","outputs = session.run(outname, inp)[0]\n","outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":529},"id":"CIRXv-gT1gQv","outputId":"f1669666-a246-4fb9-9570-8a688b515490"},"outputs":[],"source":["ori_images = [img.copy()]\n","\n","for i,(batch_id,x0,y0,x1,y1,cls_id,score) in enumerate(outputs):\n","    image = ori_images[int(batch_id)]\n","    box = np.array([x0,y0,x1,y1])\n","    box -= np.array(dwdh*2)\n","    box /= ratio\n","    box = box.round().astype(np.int32).tolist()\n","    cls_id = int(cls_id)\n","    score = round(float(score),3)\n","    name = names[cls_id]\n","    color = colors[name]\n","    name += ' '+str(score)\n","    cv2.rectangle(image,box[:2],box[2:],color,2)\n","    cv2.putText(image,name,(box[0], box[1] - 2),cv2.FONT_HERSHEY_SIMPLEX,0.75,[225, 255, 255],thickness=2)\n","\n","Image.fromarray(ori_images[0])"]}],"metadata":{"accelerator":"GPU","colab":{"name":"YOLOv7ONNXandTRT.ipynb","provenance":[{"file_id":"https://github.com/WongKinYiu/yolov7/blob/main/tools/YOLOv7onnx.ipynb","timestamp":1715164177833}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
